{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562aeff3",
   "metadata": {
    "id": "562aeff3"
   },
   "source": [
    "# Trabajo Práctico 2 de Aprendizaje Automático Profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa305a9",
   "metadata": {
    "id": "5fa305a9"
   },
   "source": [
    "> **Integrantes**: Candela Spitale | Fernando Cardellino | Carina Giovine | Carlos Serra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182fcfbb",
   "metadata": {
    "id": "182fcfbb"
   },
   "source": [
    "## Inicialización de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb813df3",
   "metadata": {
    "id": "cb813df3"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import bz2\n",
    "import json\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237b148f",
   "metadata": {
    "id": "237b148f",
    "outputId": "e6dc5476-2dbe-4430-91a4-f7c9c3532324"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu111'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbcbf0d",
   "metadata": {
    "id": "0dbcbf0d",
    "outputId": "4405551b-0f54-487b-83c1-3a8ebcafa67d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63037b69",
   "metadata": {
    "id": "63037b69"
   },
   "outputs": [],
   "source": [
    "# para usar GPU\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47a924d",
   "metadata": {
    "id": "b47a924d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  945M  100  945M    0     0  35.4M      0  0:00:26  0:00:26 --:--:-- 35.6M\n",
      "meli-challenge-2019/\n",
      "meli-challenge-2019/spanish.test.jsonl.gz\n",
      "meli-challenge-2019/portuguese.validation.jsonl.gz\n",
      "meli-challenge-2019/portuguese.train.jsonl.gz\n",
      "meli-challenge-2019/spanish.train.jsonl.gz\n",
      "meli-challenge-2019/spanish_token_to_index.json.gz\n",
      "meli-challenge-2019/portuguese_token_to_index.json.gz\n",
      "meli-challenge-2019/spanish.validation.jsonl.gz\n",
      "meli-challenge-2019/portuguese.test.jsonl.gz\n"
     ]
    }
   ],
   "source": [
    "# Descargamos los datasets\n",
    "!curl -L https://cs.famaf.unc.edu.ar/\\~ccardellino/resources/diplodatos/meli-challenge-2019.tar.bz2 -o ./data/meli-challenge-2019.tar.bz2\n",
    "!tar jxvf ./data/meli-challenge-2019.tar.bz2 -C ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a214edd",
   "metadata": {
    "id": "4a214edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  780M  100  780M    0     0  33.5M      0  0:00:23  0:00:23 --:--:-- 34.8M\n"
     ]
    }
   ],
   "source": [
    "# Descargamos word embeddings\n",
    "!curl -L https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2 -o ./data/SBW-vectors-300-min5.txt.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37eff0",
   "metadata": {
    "id": "4d37eff0"
   },
   "source": [
    "## 0. Análisis y Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63ffbbb",
   "metadata": {
    "id": "f63ffbbb",
    "outputId": "1ca55d9e-cc70-4a9e-e3af-343c2e0edba7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 32.8 s, total: 2min 29s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "meli_df_train = pd.read_json(\n",
    "    './data/meli-challenge-2019/spanish.train.jsonl.gz', lines=True)\n",
    "\n",
    "meli_df_val = pd.read_json(\n",
    "    './data/meli-challenge-2019/spanish.validation.jsonl.gz',lines=True)\n",
    "\n",
    "meli_df_test = pd.read_json(\n",
    "    './data/meli-challenge-2019/spanish.test.jsonl.gz',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba1290",
   "metadata": {
    "id": "10ba1290"
   },
   "source": [
    "Vemos qué presenta cada conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806a773e",
   "metadata": {
    "id": "806a773e",
    "outputId": "5efbe4de-c04d-4422-cbb2-db1b9120ba0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Entrenamiento\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4895280 entries, 0 to 4895279\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   language         object\n",
      " 1   label_quality    object\n",
      " 2   title            object\n",
      " 3   category         object\n",
      " 4   split            object\n",
      " 5   tokenized_title  object\n",
      " 6   data             object\n",
      " 7   target           int64 \n",
      " 8   n_labels         int64 \n",
      " 9   size             int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 373.5+ MB\n",
      "\n",
      "Datos nulos\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language           0\n",
       "label_quality      0\n",
       "title              0\n",
       "category           0\n",
       "split              0\n",
       "tokenized_title    0\n",
       "data               0\n",
       "target             0\n",
       "n_labels           0\n",
       "size               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Conjunto de Entrenamiento\\n\")\n",
    "meli_df_train.info()\n",
    "meli_df_train.head(3)\n",
    "print(\"\\nDatos nulos\\n\")\n",
    "meli_df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a3fc4d6",
   "metadata": {
    "id": "2a3fc4d6",
    "outputId": "0b9da10d-1eff-4634-cb9f-b1e10d78bbfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Validación\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1223820 entries, 0 to 1223819\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count    Dtype \n",
      "---  ------           --------------    ----- \n",
      " 0   language         1223820 non-null  object\n",
      " 1   label_quality    1223820 non-null  object\n",
      " 2   title            1223820 non-null  object\n",
      " 3   category         1223820 non-null  object\n",
      " 4   split            1223820 non-null  object\n",
      " 5   tokenized_title  1223820 non-null  object\n",
      " 6   data             1223820 non-null  object\n",
      " 7   target           1223820 non-null  int64 \n",
      " 8   n_labels         1223820 non-null  int64 \n",
      " 9   size             1223820 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 93.4+ MB\n",
      "\n",
      "Datos nulos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language           0\n",
       "label_quality      0\n",
       "title              0\n",
       "category           0\n",
       "split              0\n",
       "tokenized_title    0\n",
       "data               0\n",
       "target             0\n",
       "n_labels           0\n",
       "size               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Conjunto de Validación\\n\")\n",
    "meli_df_val.info()\n",
    "meli_df_val.head(3)\n",
    "print(\"\\nDatos nulos\")\n",
    "meli_df_val.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43206dc0",
   "metadata": {
    "id": "43206dc0",
    "outputId": "8257a313-4aaa-4daa-ad2f-76143ef19726",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de Test\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63680 entries, 0 to 63679\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   language         63680 non-null  object\n",
      " 1   label_quality    63680 non-null  object\n",
      " 2   title            63680 non-null  object\n",
      " 3   category         63680 non-null  object\n",
      " 4   split            63680 non-null  object\n",
      " 5   tokenized_title  63680 non-null  object\n",
      " 6   data             63680 non-null  object\n",
      " 7   target           63680 non-null  int64 \n",
      " 8   n_labels         63680 non-null  int64 \n",
      " 9   size             63680 non-null  int64 \n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 4.9+ MB\n",
      "\n",
      "Datos nulos\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language           0\n",
       "label_quality      0\n",
       "title              0\n",
       "category           0\n",
       "split              0\n",
       "tokenized_title    0\n",
       "data               0\n",
       "target             0\n",
       "n_labels           0\n",
       "size               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Conjunto de Test\\n\")\n",
    "meli_df_test.info()\n",
    "meli_df_test.head(3)\n",
    "print(\"\\nDatos nulos\\n\")\n",
    "meli_df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076dc61",
   "metadata": {
    "id": "9076dc61"
   },
   "source": [
    "Los 3 conjuntos no presentan datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6d60c1",
   "metadata": {
    "id": "7c6d60c1",
    "outputId": "bfc54d1f-d995-4098-faa7-000dfa79ea22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de categorías de train 632\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de categorías de train {}\".format(len(meli_df_train.category.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0511063",
   "metadata": {
    "id": "f0511063",
    "outputId": "3c120b89-0a3a-4d27-cdb0-b698d90d10d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de categorías de train 632\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de categorías de train {}\".format(len(meli_df_val.category.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd52115d",
   "metadata": {
    "id": "cd52115d",
    "outputId": "9307cc64-85d3-44b2-9fdd-7934373b768c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de categorías de train 632\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de categorías de train {}\".format(len(meli_df_test.category.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4308c18a",
   "metadata": {
    "id": "4308c18a",
    "outputId": "cc676501-0a3b-4f9c-9a5b-7d7f958e54db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de títulos de train 4895280\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de títulos de train {}\".format(len(meli_df_train.title.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ff3cc0",
   "metadata": {
    "id": "f4ff3cc0",
    "outputId": "c64db38a-747b-4df9-8c38-ac506b9905e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de títulos de val 1223820\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de títulos de val {}\".format(len(meli_df_val.title.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbe94a6e",
   "metadata": {
    "id": "dbe94a6e",
    "outputId": "ce8b3989-491e-4231-91de-cd4864dc2add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad de títulos de test 63680\n"
     ]
    }
   ],
   "source": [
    "print(\"cantidad de títulos de test {}\".format(len(meli_df_test.title.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c0f5e09",
   "metadata": {
    "id": "0c0f5e09"
   },
   "outputs": [],
   "source": [
    "#!curl -L https://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.txt.bz2 -o ./data/SBW-vectors-300-min5.txt.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "103598e2",
   "metadata": {
    "id": "103598e2"
   },
   "outputs": [],
   "source": [
    "#embeddings = pd.read_csv('./data/SBW-vectors-300-min5.txt.bz2', nrows=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a188b2a",
   "metadata": {
    "id": "8a188b2a"
   },
   "outputs": [],
   "source": [
    "#embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e1ee8",
   "metadata": {
    "id": "f92e1ee8"
   },
   "source": [
    "## 1. Hacer un preprocesamiento de los datos\n",
    "\n",
    "Los conjuntos json de `spanish.{split}.json` ya están preprocesados y tokenizados, con las columnas `data` (referente a **title**) y `target` (referente a **category**). Esto se hizo en el [repositorio de la materia](https://github.com/DiploDatos/AprendizajeProfundo) en el archivo `experiment/preprocess_meli_data.ipynb`. Por lo cual, los utilizaremos directamente accediendo a estas columnas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425e269",
   "metadata": {
    "id": "e425e269"
   },
   "source": [
    "## 2. Tener un manejador del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ec8c5b",
   "metadata": {
    "id": "68ec8c5b"
   },
   "outputs": [],
   "source": [
    "class MeliChallengeDataset(IterableDataset):\n",
    "    def __init__(self,\n",
    "                 dataset_path,\n",
    "                 random_buffer_size=2048):\n",
    "        assert random_buffer_size > 0\n",
    "        self.dataset_path = dataset_path\n",
    "        self.random_buffer_size = random_buffer_size\n",
    "\n",
    "        with gzip.open(self.dataset_path, \"rt\") as dataset:\n",
    "            item = json.loads(next(dataset).strip())\n",
    "            self.n_labels = item[\"n_labels\"]\n",
    "            self.dataset_size = item[\"size\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        try:\n",
    "            with gzip.open(self.dataset_path, \"rt\") as dataset:\n",
    "                shuffle_buffer = []\n",
    "\n",
    "                for line in dataset:\n",
    "                    item = json.loads(line.strip())\n",
    "                    item = {\n",
    "                        \"data\": item[\"data\"],\n",
    "                        \"target\": item[\"target\"]\n",
    "                    }\n",
    "\n",
    "                    if self.random_buffer_size == 1:\n",
    "                        yield item\n",
    "                    else:\n",
    "                        shuffle_buffer.append(item)\n",
    "\n",
    "                        if len(shuffle_buffer) == self.random_buffer_size:\n",
    "                            random.shuffle(shuffle_buffer)\n",
    "                            for item in shuffle_buffer:\n",
    "                                yield item\n",
    "                            shuffle_buffer = []\n",
    "\n",
    "                if len(shuffle_buffer) > 0:\n",
    "                    random.shuffle(shuffle_buffer)\n",
    "                    for item in shuffle_buffer:\n",
    "                        yield item\n",
    "        except GeneratorExit:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110e74ea",
   "metadata": {
    "id": "110e74ea"
   },
   "outputs": [],
   "source": [
    "train_dataset = MeliChallengeDataset('./data/meli-challenge-2019/spanish.train.jsonl.gz')\n",
    "\n",
    "val_dataset = MeliChallengeDataset('./data/meli-challenge-2019/spanish.validation.jsonl.gz')\n",
    "\n",
    "test_dataset = MeliChallengeDataset('./data/meli-challenge-2019/spanish.test.jsonl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd80284",
   "metadata": {
    "id": "4dd80284"
   },
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=None, min_length=1):\n",
    "        assert max_length is None or min_length <= max_length\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        if self.max_length:\n",
    "            max_length = self.max_length\n",
    "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "        else:\n",
    "            max_length = max(self.min_length, max(seq_lengths))\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.LongTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e831b9d0",
   "metadata": {
    "id": "e831b9d0"
   },
   "outputs": [],
   "source": [
    "pad_sequences = PadSequences(\n",
    "                    pad_value=0,\n",
    "                    max_length=None,\n",
    "                    min_length=1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128,\n",
    "                          collate_fn=pad_sequences, drop_last=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=128,\n",
    "                         collate_fn=pad_sequences, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, \n",
    "                         collate_fn=pad_sequences, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e4fde",
   "metadata": {
    "id": "ee8e4fde"
   },
   "source": [
    "## 3. Crear una clase para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb8a25e9",
   "metadata": {
    "id": "fb8a25e9"
   },
   "outputs": [],
   "source": [
    "class CNN_Classifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings_path, \n",
    "                 token_to_index,\n",
    "                 vector_size,\n",
    "                 freeze_embedings,\n",
    "                 hidden1_size,\n",
    "                 filters_count,\n",
    "                 filters_length):\n",
    "\n",
    "        super().__init__()\n",
    "        with gzip.open(token_to_index, \"rt\") as fh:\n",
    "              token_to_index = json.load(fh)\n",
    "        embeddings_matrix = torch.randn(len(token_to_index), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        \n",
    "        with bz2.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in token_to_index:\n",
    "                    embeddings_matrix[token_to_index[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "      \n",
    "        \n",
    "        self.convs = []\n",
    "        for filter_lenght in filters_length:\n",
    "            self.convs.append(\n",
    "                nn.Conv1d(vector_size, filters_count, filter_lenght) #(in_channels, out_channels, kernel_size)\n",
    "            )\n",
    "        self.convs = nn.ModuleList(self.convs)\n",
    "        self.fc = nn.Linear(filters_count * len(filters_length), hidden1_size)\n",
    "        self.output = nn.Linear(hidden1_size, 632)\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    @staticmethod\n",
    "    def conv_global_max_pool(x, conv):\n",
    "        return F.relu(conv(x).transpose(1, 2).max(1)[0])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x).transpose(1, 2)  \n",
    "        x = [self.conv_global_max_pool(x, conv) for conv in self.convs]\n",
    "        x = torch.cat(x, dim=1)#flatten de la matriz\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.output(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37adee",
   "metadata": {
    "id": "1b37adee"
   },
   "source": [
    "## 4. Hacer logs de entrenamiento. Usar MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e526044b",
   "metadata": {
    "id": "e526044b"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss_function, trainloader, epochs, use_tqdm=True):\n",
    "    model.train()  # Tell the model to set itself to \"train\" mode.\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = []\n",
    "        running_loss_displayed = 0.0\n",
    "        pbar = tqdm(trainloader) if use_tqdm else trainloader\n",
    "        for step, data in enumerate(pbar, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data[\"data\"].to(device)\n",
    "            labels = data[\"target\"].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss.append(loss.item())\n",
    "            running_loss_displayed += loss.item()\n",
    "            if use_tqdm and step > 0 and step % 50 == 0: # print every 50 mini-batches\n",
    "                pbar.set_description(f\"[{epoch + 1}, \\\n",
    "                                    {step}] loss: {running_loss_displayed / step:.4g}\")\n",
    "    return running_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f717f67",
   "metadata": {
    "id": "7f717f67"
   },
   "source": [
    "Para ver cómo predice el modelo en un dataset que no conoce (dataset de `test`) necesitamos usar una métrica de evaluación. Dado que estamos con un problema multiclase, en este caso vamos a usar el **balance accuracy score**. \n",
    "\n",
    "A fin de probar configuraciones, arquitecturas o hiperparámetros y encontrar los mejores para el conjunto de `test`, utilizaremos esta métrica en el conjunto de `entrenamiento` y `validación`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6011ba4a",
   "metadata": {
    "id": "6011ba4a"
   },
   "outputs": [],
   "source": [
    "def train_and_eval(model, optimizer, loss_function, trainloader, epochs,\n",
    "                   valloader, use_tqdm=True):\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_balanced_accuracy': []}\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        print(\"Iniciando train con datos de entrenamiento\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(trainloader) if use_tqdm else trainloader\n",
    "        for step, data in enumerate(pbar, 1):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = data[\"data\"].to(device)\n",
    "            labels = data[\"target\"].to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs.view(inputs.shape[0], -1))\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if use_tqdm and step > 0 and step % 50 == 0:\n",
    "                pbar.set_description(\n",
    "                    f\"[{epoch + 1}, {step}] loss: {running_loss / step:.4g}\")\n",
    "\n",
    "        history['train_loss'].append((epoch, running_loss / step))\n",
    "\n",
    "        # At the end of the epoch, evaluate model on validation\n",
    "        print(\"Iniciando eval con datos de validación\")\n",
    "        model.eval();  # Activate evaluation mode\n",
    "        running_loss = 0.0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(valloader) if use_tqdm else valloader\n",
    "            for step, data in enumerate(pbar, 1):\n",
    "                inputs = data[\"data\"].to(device)\n",
    "                labels = data[\"target\"].to(device)\n",
    "                outputs = model(inputs.view(inputs.shape[0], -1))\n",
    "                running_loss += loss_function(outputs, labels).item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        history['val_balanced_accuracy'].append(balanced_accuracy_score(y_true, y_pred))\n",
    "        history['val_loss'].append((epoch, running_loss / step))\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ba0cd1",
   "metadata": {
    "id": "89ba0cd1"
   },
   "outputs": [],
   "source": [
    "def test_model(model, dataloader, prefix='test_', use_tqdm=True):\n",
    "    model.eval();  # Activate evaluation mode\n",
    "    running_loss = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader) if use_tqdm else dataloader\n",
    "        print(\"Iniciando experimento con conjunto de test\")\n",
    "        for data in pbar:\n",
    "            inputs = data[\"data\"].to(device)\n",
    "            labels = data[\"target\"].to(device)\n",
    "\n",
    "            outputs = model(inputs.view(inputs.shape[0], -1))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    return {\n",
    "        prefix + 'balanced_accuracy': balanced_accuracy_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c30b44e2",
   "metadata": {
    "id": "c30b44e2"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model, epochs, trainloader, valloader, testloader=None, \n",
    "                    optimizer_class=optim.SGD, lr=0.001, weight_decay=0.0,\n",
    "                    use_tqdm=True):\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr,\n",
    "                                weight_decay=weight_decay)\n",
    "    history = train_and_eval(\n",
    "        model, optimizer, loss_function, trainloader, epochs,\n",
    "        valloader=valloader, use_tqdm=use_tqdm)\n",
    "    \n",
    "    if testloader:\n",
    "        test_results = test_model(model, testloader, use_tqdm=use_tqdm)\n",
    "\n",
    "    experiment = {\n",
    "        'arquitecture': str(model), 'loss': str(loss_function),\n",
    "        'epochs': epochs, 'lr': lr, 'optimizer': str(optimizer_class),\n",
    "        'weight_decay': weight_decay\n",
    "    }\n",
    "    \n",
    "    experiment.update(history)\n",
    "\n",
    "    if testloader:\n",
    "        experiment.update(test_results)\n",
    "    \n",
    "    return experiment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac54cf5",
   "metadata": {
    "id": "6ac54cf5"
   },
   "outputs": [],
   "source": [
    "def run__mlflow_experiment(indice, epochs,\n",
    "                           hidden1_size,\n",
    "                           filters_count,\n",
    "                           filters_length,\n",
    "                           optimizer_class,\n",
    "                           lr,\n",
    "                           run_name,\n",
    "                           run_in_test=False):\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # como primer parámetro pasamos el archivo con los embeddings descargados,\n",
    "        # como segundo parámetro pasamos los títulos tokenizados y las categorías \n",
    "        # tokenizadas con sus respectivos índices, \n",
    "        # resultante de la tokenización hecha en la carpeta experiments de la materia\n",
    "        model = CNN_Classifier(\"./data/SBW-vectors-300-min5.txt.bz2\",\n",
    "                               \"./data/meli-challenge-2019/spanish_token_to_index.json.gz\",\n",
    "                               300, True, \n",
    "                               hidden1_size,\n",
    "                               filters_count,\n",
    "                               filters_length)\n",
    "        \n",
    "        model.to(device)\n",
    "        epochs = epochs\n",
    "        \n",
    "        mlflow.log_param(\"model_name\", \"CNN_Classifier\")\n",
    "        mlflow.log_param(\"freeze_embedding\", True)\n",
    "        mlflow.log_params({\n",
    "            \"embedding_size\": 300,\n",
    "            \"filters_count\": filters_count,\n",
    "            \"filters_length\": filters_length,\n",
    "            \"fc_size\": hidden1_size,\n",
    "            \"optimizer\": optimizer_class,\n",
    "            \"lr\": lr\n",
    "        })\n",
    "        print(\"Exploring \", optimizer_class, lr)\n",
    "        \n",
    "        if run_in_test:\n",
    "            experiment = run_experiment(model, epochs, \n",
    "                                        train_loader, val_loader, \n",
    "                                        testloader=test_loader, \n",
    "                                        optimizer_class=optimizer_class, lr=lr)\n",
    "        else:\n",
    "            experiment = run_experiment(model, epochs, train_loader, val_loader, \n",
    "                                        optimizer_class=optimizer_class, lr=lr)\n",
    "            \n",
    "        for m in range(epochs):\n",
    "            mlflow.log_metrics({\n",
    "                'train_loss': experiment['train_loss'][m][1],\n",
    "                'val_loss':experiment['val_loss'][m][1],\n",
    "                'val_balanced_accuracy':experiment['val_balanced_accuracy'][m],    \n",
    "            },m)\n",
    "    \n",
    "        if run_in_test:\n",
    "            mlflow.log_metrics({\n",
    "                'test_balanced_accuracy':experiment['test_balanced_accuracy']\n",
    "            })\n",
    "\n",
    "        print(\"Creando artefacto de MlFlow\")\n",
    "        with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "            targets = []\n",
    "            predictions = []\n",
    "            for batch in tqdm(val_loader):\n",
    "                inputs = batch[\"data\"].to(device)\n",
    "                labels = batch[\"target\"].to(device)\n",
    "                output = model(inputs)\n",
    "                targets.extend(labels.cpu().numpy())\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(\n",
    "                f\"{tmpdirname}/predictions_iteracion{indice}.csv.gz\", \n",
    "                    index=False\n",
    "            )\n",
    "            mlflow.log_artifact(f\"{tmpdirname}/predictions_iteracion{indice}.csv.gz\")\n",
    "        \n",
    "        return experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bc36e",
   "metadata": {
    "id": "3d8bc36e"
   },
   "source": [
    "En todos los runs del experimento hacemos una red convolucional de 3 capas covolucionales (a las cuales luego aplicamos max pooling) y 2 capa lienales con los siguientes tamaños:\n",
    "\n",
    "* Capas convolucionales:   \n",
    "    * Canales de entrada: 300 (coincidente con la dimensión de los embbedings),  \n",
    "    * Canales de salida: 100 (coincidente con la cantidad de filtros),  \n",
    "    * Tamaño del kernel/filtro: 2, 3 y 4 (en cada capa respectivamente)\n",
    "* Capas lineales o full connected:  \n",
    "    * Primer capa: 1024, considerando que el tamaño de input es 300  \n",
    "    * Capa de salida: 1024 que discrimina entre 632 categorías de salida (casi el doble que el tamaño de input)\n",
    "\n",
    "Además, utilizamos `3` **épocas**.\n",
    "\n",
    "Variamos únicamente el **optimizador** y la **taza de aprendizaje**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b9d8f7",
   "metadata": {
    "id": "17b9d8f7",
    "outputId": "8be0d387-e5f1-49f2-c031-037f78df7adc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/29 22:37:18 INFO mlflow.tracking.fluent: Experiment with name 'experiment_CNN_Classifier_w_3epochs' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring  <class 'torch.optim.adam.Adam'> 0.0001\n",
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f994131d3be4457c87dcf526bb0f447d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1580b978ab410eb02b4a5f2080aaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d0599e869043d390fcc3e7c3c0198b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad51ecc969446e3910bc3819983e831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385b688086fb499c8af37cacb50a105d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7ca4700dc2404eaf31d347df11301c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando artefacto de MlFlow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd17a064c6f421881483c668914ccae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring  <class 'torch.optim.adam.Adam'> 0.001\n",
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abce4eacfcc4821a4e6ff04ab7f354d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4803ce4f354d74a238c2edf48732ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7498227247ab4772b7da810ee6c11ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2d74abca704776a329971a420b5401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8ae6ae416a4e1e99872d40e482c4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbea5889bb42407a8a4c1fb4ec53c86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando artefacto de MlFlow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aaa2b003904136a40921892dda795e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring  <class 'torch.optim.rmsprop.RMSprop'> 0.0001\n",
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3762dbbe21664e179b9cc4056742d6d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c8faad2ecf4b1abba85d35e47947b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a36b730dea64b80a35113502ef7873e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c8f50a4ad54e49b6fb7019915f8327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2373ea14384455a9cec6e7e3e80c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004da4c691d543f98c8fd5d220da5179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando artefacto de MlFlow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685ab7852bec4cb7a7fd4a0932afdc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring  <class 'torch.optim.rmsprop.RMSprop'> 0.001\n",
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69615aefd6c430b90080a736418db99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780bd58f9a4340fb9637ebea7ab7e5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71bb4583a564d8f9f75ab4fa5006a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a269ef5fb53c4629839ab4999af7afd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab286139e654d1f874914ae36abe934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9edc808b0d943a98e523e02b2704ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creando artefacto de MlFlow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8af4c3af1b0415aae2b88ef51bda824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3\n",
    "FILTERS_COUNT = 100\n",
    "FILTERS_LENGTH = [2, 3, 4]\n",
    "op_experiments = []\n",
    "mlflow.set_experiment(experiment_name=f\"experiment_CNN_Classifier_w_{epochs}epochs\")\n",
    "indice = 0\n",
    "\n",
    "for optimizer_class in [optim.Adam, optim.RMSprop]:\n",
    "    for lr in [0.0001, 0.001]:\n",
    "\n",
    "        run_name = f\"filters_length:{FILTERS_LENGTH}-filters_count:{FILTERS_COUNT}-fc_size:1024\\\n",
    "                    op_class:{optimizer_class}_lr:{lr}\"\n",
    "        experiment=run__mlflow_experiment(indice,\n",
    "                                          epochs,\n",
    "                                          1024,\n",
    "                                          FILTERS_COUNT,\n",
    "                                          FILTERS_LENGTH,\n",
    "                                          optimizer_class,\n",
    "                                          lr,\n",
    "                                          run_name=run_name)\n",
    "        op_experiments.append(experiment)\n",
    "        indice+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c238be90",
   "metadata": {
    "id": "c238be90"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(op_experiments).to_csv(\n",
    "    f\"./data/experiments/op_experiments_w_{epochs}epochs_CNN_Classifier_FiltersCount{FILTERS_COUNT}.csv.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633cbff",
   "metadata": {
    "id": "6633cbff"
   },
   "source": [
    "## 5. Hacer un gráfico de la función de loss a lo largo de las epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd9a4e",
   "metadata": {
    "id": "02cd9a4e"
   },
   "source": [
    "Usamos MLFlow y luego edición para identificar cada run, ya que en MLFlow no se lograban ver los hiperparámetros en el gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119c4f5",
   "metadata": {
    "id": "f119c4f5"
   },
   "source": [
    "> Comparación de loss a través de las 3 épocas en conjunto de **entrenamiento** y **validación**\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1P5tM0qywbfNAsQ4zc9xdCOFdY8M87oQ_' name='train_loss'>\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1HdkVIcliO8i4K_WfunchHKjjLXcKv1Vw' name='val_loss'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59526b83",
   "metadata": {
    "id": "59526b83"
   },
   "source": [
    "## 6. Reportar performance en el conjunto de test con el mejor modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225f8230",
   "metadata": {
    "id": "225f8230",
    "outputId": "b1165901-e34b-4445-9796-610e81b5d263",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/30 09:30:43 INFO mlflow.tracking.fluent: Experiment with name 'test_experiment_CNNClassifier_w_3epochs' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring  <class 'torch.optim.adam.Adam'> 0.0001\n",
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d33e8c7eb94e4b9ed1b02675deb1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d48ad6c8ac14a758a29dd7557387aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa10aacc3a945b085dc916f35a2e1aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dcbffe3ac142c5ac9966b45ffb65b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando train con datos de entrenamiento\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a4ffa9105c4f69ba653b00c3608a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando eval con datos de validación\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47554232675a4f738ced4f730dbfa740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22ff4f0d46f4132a17dd2b88a8cbf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando experimento con conjunto de test\n",
      "Creando artefacto de MlFlow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1822305fc6584809af4df82462bcac1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3\n",
    "FILTERS_COUNT = 100\n",
    "FILTERS_LENGTH = [2, 3, 4]\n",
    "op_experiments = []\n",
    "mlflow.set_experiment(experiment_name=f\"test_experiment_CNNClassifier_w_{epochs}epochs\")\n",
    "indice = 0\n",
    "\n",
    "optimizer_class = optim.Adam\n",
    "lr = 0.0001\n",
    "\n",
    "run_name = f\"test_filters_length:{FILTERS_LENGTH}-filters_count:{FILTERS_COUNT}-fc_size:1024\\\n",
    "            op_class:{optimizer_class}_lr:{lr}\"\n",
    "\n",
    "experiment = run__mlflow_experiment(indice,\n",
    "                                  epochs,\n",
    "                                  1024,\n",
    "                                  FILTERS_COUNT,\n",
    "                                  FILTERS_LENGTH,                                    \n",
    "                                  optimizer_class,\n",
    "                                  lr,\n",
    "                                  run_name=run_name,\n",
    "                                  run_in_test=True)\n",
    "op_experiments.append(experiment)\n",
    "indice+=1\n",
    "\n",
    "pd.DataFrame(op_experiments).to_csv(\n",
    "    f\"./data/experiments/test_op_experiments_w_{epochs}epochs_CNNClassifier_FiltersCount{FILTERS_COUNT}.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfeedce",
   "metadata": {
    "id": "ecfeedce"
   },
   "source": [
    "> Performance del conjunto de test con el mejor modelo entrenado: Optim: Adam, LR: 0.0001\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1QT2IJZyvL4nzMcjUhqoTQjNumN_17DCQ' name='val_loss' name='test_balanced_accuracy'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a31c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
